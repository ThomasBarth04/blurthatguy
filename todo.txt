MVP:
1. take video input
2. split into frames
3. first we use haarcascade_frontalface_default.xml to find all unique faces and spilce them together as one frame.
4. feed that one frame into a face recogition library to train a model
4. then find a way to create box around a selected face saved from step 3 througut the entire video.
5. blur that box.
6. get chat to create frontend

Maybe:
1. rewrite from python to c++ and compile to WASM, then we can host on vercel and use node workers to run the bluring. 
2. blur from livefeed

